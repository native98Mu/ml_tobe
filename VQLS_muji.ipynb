{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0e5d5a545d47a452400ed0f023be4625769e773074f6a65de0103e9cc8585fc80",
   "display_name": "Python 3.7.10 64-bit ('paddle_quantum_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'H' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-621d3f5c9085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# 定义网络维度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mvqe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvqe_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtheta_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# 一般来说，我们利用Adam优化器来获得相对好的收敛，当然你可以改成SGD或者是RMS prop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-621d3f5c9085>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m     27\u001b[0m                                            \u001b[0mdefault_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                            dtype=dtype, is_bias=False)\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# 定义损失函数和前向传播机制\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'H' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import paddle\n",
    "from paddle_quantum.circuit import UAnsatz\n",
    "from paddle_quantum.utils import pauli_str_to_matrix\n",
    "\n",
    "# 首先生成泡利字符串表示下的哈密顿量\n",
    "# 相当于0.4*kron(I, Z) + 0.4*kron(Z, I) + 0.2*kron(X, X)\n",
    "# 其中， X，Y, Z是泡利矩阵， I是单位矩阵\n",
    "H_info = [[0.4, 'z0'], [0.4, 'z1'], [0.2, 'x0,x1']]\n",
    "\n",
    "# 超参数设置\n",
    "num_qubits = 2\n",
    "theta_size = 4\n",
    "ITR = 60\n",
    "LR = 0.4\n",
    "SEED = 999       \n",
    "\n",
    "# 把记录的关于哈密顿量的信息转化为矩阵表示\n",
    "H_matrix = pauli_str_to_matrix(H_info, num_qubits)\n",
    "class vqe_demo(paddle.nn.Layer):\n",
    "    \n",
    "    def __init__(self, shape, dtype='float64'):\n",
    "        super(vqe_demo, self).__init__()\n",
    "        \n",
    "        # 初始化一个长度为theta_size的可学习参数列表，并用[0, 2*pi]的均匀分布来填充初始值\n",
    "        self.theta = self.create_parameter(shape=shape, \n",
    "                                           default_initializer=paddle.nn.initializer.Uniform(low=0., high=2*np.pi), \n",
    "                                           dtype=dtype, is_bias=False)\n",
    "        self.H = paddle.to_tensor(H)\n",
    "        \n",
    "    # 定义损失函数和前向传播机制\n",
    "    def forward(self):\n",
    "        \n",
    "        # 初始量子电路\n",
    "        cir = UAnsatz(num_qubits)\n",
    "        \n",
    "        # 添加量子门\n",
    "        cir.ry(self.theta[0], 0)\n",
    "        cir.ry(self.theta[1], 1)\n",
    "        cir.cnot([0, 1])\n",
    "        cir.ry(self.theta[2], 0)\n",
    "        cir.ry(self.theta[3], 1)\n",
    "        \n",
    "        # 选择用量子态的向量表示\n",
    "        cir.run_state_vector()\n",
    "        \n",
    "        # 计算当前量子态下关于观测量H_info的期望值\n",
    "        # 也就是 <psi|H|psi>\n",
    "        loss = cir.expecval(H_info)\n",
    "        \n",
    "        return loss\n",
    "loss_list = []\n",
    "parameter_list = []\n",
    "\n",
    "# 定义网络维度\n",
    "vqe = vqe_demo([theta_size])\n",
    "\n",
    "# 一般来说，我们利用Adam优化器来获得相对好的收敛，当然你可以改成SGD或者是RMS prop.\n",
    "opt = paddle.optimizer.Adam(learning_rate = LR, parameters = vqe.parameters())    \n",
    "\n",
    "# 优化循环\n",
    "for itr in range(ITR):\n",
    "\n",
    "    # 前向传播计算损失函数\n",
    "    loss = vqe()\n",
    "\n",
    "    # 反向传播极小化损失函数\n",
    "    loss.backward()\n",
    "    opt.minimize(loss)\n",
    "    opt.clear_grad()\n",
    "\n",
    "    # 记录学习曲线\n",
    "    loss_list.append(loss.numpy()[0])\n",
    "    parameter_list.append(vqe.parameters()[0].numpy())\n",
    "    if itr % 10 == 0:\n",
    "        print('iter:', itr, '  loss: %.4f' % loss.numpy())\n",
    "\n",
    "\n",
    "print('计算得到的基态能量是: ', loss_list[-1])\n",
    "print('真实的基态能量为: ', np.linalg.eigh(H_matrix)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[1,2,3],[0,1,4],[0,0,3]])\n",
    "x = np.array([1,1,1])\n",
    "c = A.dot(x)\n",
    "print(c)\n",
    "d = x.transpose().dot(A.transpose())\n",
    "print(d)\n",
    "e = np.array([[1],[2]])\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = np.identity(2)\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "\n",
    "A_0 = np.identity(8)\n",
    "A_1 = np.kron(np.kron(X, Z), Id)\n",
    "A_2 = np.kron(np.kron(X, Id), Id)\n",
    "\n",
    "A_num = c[0] * A_0 + c[1] * A_1 + c[2] * A_2\n",
    "b = np.ones(8) / np.sqrt(8)\n",
    "print(\"A = \\n\", A_num)\n",
    "print(\"b = \\n\", b)\n",
    "A_inv = np.linalg.inv(A_num)\n",
    "print('Ainv = \\n',A_inv)\n",
    "# c = np.dot(A_num,A_inv)\n",
    "# print('c = \\n ',c)\n",
    "# x = np.dot(A_inv, b)\n",
    "# c_probs = (x / np.linalg.norm(x)) ** 2\n",
    "# d = np.dot(A_num,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}