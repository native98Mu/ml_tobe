{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0e5d5a545d47a452400ed0f023be4625769e773074f6a65de0103e9cc8585fc80",
   "display_name": "Python 3.7.10 64-bit ('paddle_quantum_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 线性系统求解\n",
    "$Ax = b  $\n",
    "$$A = c_0A_0+c_1A_1+c_2A_2=\\mathbb{I}+0.2X_0Z_1+0.2X_0$$\n",
    "$$|b\\rangle = U|0\\rangle = H_0H_1H_2|0\\rangle$$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import paddle \n",
    "from paddle import matmul\n",
    "from paddle_quantum.circuit import UAnsatz\n",
    "from paddle_quantum.utils import random_pauli_str_generator, pauli_str_to_matrix, dagger\n",
    "#参数设置\n",
    "num_qubit = 3  #number of qubits\n",
    "num_shots = 10**6 # Number of quantum measurements\n",
    "tot_qubits = num_qubit+1 # Addition of an ancillary qubit\n",
    "ancilla_idx = num_qubit #Index of the ancillary qubit (last position)\n",
    "ITR = 40 #训练迭代次数\n",
    "LR = 0.5 #学习速率\n",
    "seed = 2 # Seed for random number generator\n",
    "#coefficient of A=c_0 A_0 + c_1 A_1 ...\n",
    "c = np.array([1,0.2,0.2])\n",
    "c = paddle.to_tensor(c,dtype = 'complex128')\n"
   ]
  },
  {
   "source": [
    "## update部分\n",
    "### 电路部分改进\n",
    "1. 初始的版本中，只使用了单层的ry门，导致表达性不强，所以在update版本中选择了三层的layer\n",
    "2. paper中的电路间产生纠缠使用了cz门，自行构造替换"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 各门电路定义\n",
    "U操作: $U|0\\rangle = |b\\rangle$  \n",
    "\n",
    "A操作: $A = \\mathbb{I}+0.2X_0Z_1+0.2X_0$\n",
    "\n",
    "要训练的量子网络V $V|0\\rangle = |x\\rangle$ 电路的结构为多层的ry操作，通过cnot产生纠缠\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义门电路U U|0> = |b>\n",
    "def U_b(cir):\n",
    "    for idx in range(num_qubit):\n",
    "        cir.h(idx)\n",
    "# 定义受控酉矩阵\n",
    "def CA(cir,idx):\n",
    "    if idx == 0:\n",
    "        # Identity operation\n",
    "        None\n",
    "    elif idx == 1:\n",
    "        cir.cnot([ancilla_idx,0])\n",
    "        #构造cz门\n",
    "        cir.h(1)\n",
    "        cir.cnot([ancilla_idx,1])\n",
    "        cir.h(1)\n",
    "\n",
    "    elif idx == 2:\n",
    "        cir.cnot([ancilla_idx,0])\n",
    "#定义变分量子电路 使得|x> = V|0>\n",
    "def variational_block(cir,theta):\n",
    "    '''\n",
    "    QNN\n",
    "    '''\n",
    "    #第一层是给除附加位外所有量子比特施加h门\n",
    "    for idx in range(num_qubit):\n",
    "        cir.h(idx)\n",
    "    #单层的全y门\n",
    "    for idx, element in enumerate(theta):\n",
    "        if idx % 3 == 0:\n",
    "            cir.ry(element,0)\n",
    "        elif idx % 3 == 1:\n",
    "            cir.ry(element,1)\n",
    "        elif idx % 3 == 2:\n",
    "            cir.ry(element,2)\n",
    "        \n",
    "        if idx == 2:\n",
    "            #cz 0-1\n",
    "            cir.h(1)\n",
    "            cir.cnot([0,1])\n",
    "            cir.h(1)\n",
    "            #cz 0-2\n",
    "            cir.h(2)\n",
    "            cir.cnot([0,2])\n",
    "            cir.h(2)\n",
    "        elif idx == 5:\n",
    "            #cz 1-2\n",
    "            cir.h(2)\n",
    "            cir.cnot([1,2])\n",
    "            cir.h(2)\n",
    "            #cz 0-2\n",
    "            cir.h(2)\n",
    "            cir.cnot([0,2])\n",
    "            cir.h(2)"
   ]
  },
  {
   "source": [
    "## hadamard test\n",
    "根据hadamard test电路要求，按顺序放好构建的门序列。  \n",
    "\n",
    "获取系统最终状态里附加位为$|0\\rangle$的概率（由于paddle_quantum中没有可以直接测量系统中某条电路状态的方法，故根据测量原理，构建投影算子M，计算辅助位为$|0\\rangle$概率）\n",
    "\n",
    "根据hadamard test算法，只需要对辅助比特进行计算基测量，测量得到结果为$|0\\rangle$的概率与两量子态内积有：$Re(\\langle\\phi_1|\\phi\\rangle = 2*p_0 -1$ 类似的，虚数部分需要添加相位变换s gate，相同的推导可以得到虚数部分$\\operatorname{Im}\\left(\\left\\langle\\phi_{1} \\mid \\phi_{2}\\right\\rangle\\right)=2 p_{0}-1$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hadamard test\n",
    "def local_hadamard_test(theta,l = None,lp=None,j = None,part = None):\n",
    "    # print('test: l,lp,j', l,lp,j)\n",
    "    #初始化电路\n",
    "    cir = UAnsatz(tot_qubits)#需要附加位\n",
    "    #作用在附加位上的H门\n",
    "    cir.h(ancilla_idx)\n",
    "    #如果要计算的是虚数部，附加位还需要加一个相位门\n",
    "    #phase gate\n",
    "    if part == 'Im' or part == 'im':\n",
    "        cir.s(ancilla_idx)\n",
    "        cir.z(ancilla_idx)\n",
    "    #生成一个向量｜x>\n",
    "    variational_block(cir,theta)\n",
    "    #使用A_l\n",
    "    CA(cir,l)\n",
    "    #添加U_b\n",
    "    U_b(cir)\n",
    "    #添加受控z\n",
    "    if j != -1:\n",
    "        # #cz gate\n",
    "        # cir.s(ancilla_idx)\n",
    "        # cir.s(ancilla_idx)\n",
    "        # cir.s(ancilla_idx)\n",
    "        # cir.cnot([ancilla_idx,j])\n",
    "        # cir.rz(cz_theta,j)\n",
    "        # cir.cnot([ancilla_idx,j])\n",
    "        # cir.rz(-cz_theta,j)\n",
    "        cir.h(j)\n",
    "        cir.cnot([ancilla_idx,j])\n",
    "        cir.h(j)\n",
    "    #添加U\n",
    "    U_b(cir)\n",
    "    #contralled gate为A的共轭转置\n",
    "    CA(cir,lp)\n",
    "    #辅助位第二个hadamard门\n",
    "    cir.h(ancilla_idx)\n",
    "    #对辅助比特为｜0>进行观测\n",
    "    fi_state = cir.run_state_vector()\n",
    "    state = paddle.reshape(fi_state, shape=(2**tot_qubits, 1))\n",
    "    # 构造投影矩阵M\n",
    "    M_0 = np.array([[1,0],[0,0]])\n",
    "    Id = np.identity(2)\n",
    "    M = np.kron(np.kron(Id,Id),Id)\n",
    "    M = np.kron(M,M_0)\n",
    "    M = paddle.to_tensor(M)\n",
    "    #计算辅助位为|0>概率\n",
    "    M = paddle.matmul(dagger(M), M)\n",
    "    p0 = paddle.matmul(paddle.matmul(dagger(state), M), state) \n",
    "    #return 2*p0 - 1\n",
    "    b2t = paddle.to_tensor(2.0)\n",
    "    p0 = paddle.matmul(b2t,p0)\n",
    "    b1t = paddle.to_tensor(1.0)\n",
    "    po = paddle.subtract(p0,b1t)\n",
    "    return p0"
   ]
  },
  {
   "source": [
    "## local cost function中重要系数$\\mu$计算\n",
    "根据论文中描述，可以知道局部cost function需使用hadamard test计算。$\\delta_{l l^{\\prime}}^{(j)}=\\left\\langle\\mathbf{0}\\left|V^{\\dagger} A_{l^{\\prime}}^{\\dagger} U\\left(\\left|0_{j}\\right\\rangle\\left\\langle 0_{j}\\right| \\otimes \\mathbb{I}_{\\bar{J}}\\right) U^{\\dagger} A_{l} V\\right| \\mathbf{0}\\right\\rangle$，其中$\\left|0_{j}\\right\\rangle\\left\\langle 0_{j}\\right|=\\left(\\mathbb{I}_{j},Z_j)/2\\right.$，所以有\n",
    "$\\delta_{l l^{\\prime}}^{(j)}=\\beta_{l l^{\\prime}}+\\left\\langle\\mathbf{0}\\left|V^{\\dagger} A_{l^{\\prime}}^{\\dagger} U\\left(Z_{j} \\otimes \\mathbb{I}_{\\bar{\\jmath}}\\right) U^{\\dagger} A_{l} V\\right| \\mathbf{0}\\right\\rangle$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算local cost function中mu的系数\n",
    "def mu(theta,l = None,lp=None,j=None):\n",
    "    # print('mu: l,lp,j= ',l,lp,j)\n",
    "    mu_real = local_hadamard_test(theta,l = l,lp = lp,j = j,part='Re')\n",
    "    mu_imag = local_hadamard_test(theta,l = l, lp = lp, j = j, part= 'Im')\n",
    "    jj = paddle.to_tensor([1j],dtype = 'complex128')\n",
    "    muval = mu_real+ mu_imag * jj\n",
    "    return muval"
   ]
  },
  {
   "source": [
    "## local cost function 计算\n",
    "首先对$\\langle x|A^{\\dagger}A|x\\rangle$的评估  \n",
    "接着利用hadamard test算得的mu，求和计算loss值  \n",
    "求loss值的过程中，三层循环相当于是对每个$A_l,A^{\\dagger}_l,Z_j$做了一遍测量 即要做$3*3*3 = 27$次"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化 先计算 <x|A'A|x> 分母\n",
    "def psi_norm(theta):\n",
    "    '''Returns the normalization constant <psi|psi>'''\n",
    "    norm = 0\n",
    "    norm = paddle.to_tensor(norm,dtype = 'complex128')\n",
    "    for l in range(c.size):\n",
    "        for lp in range(c.size):\n",
    "            norm = norm+c[l]*paddle.conj(c[lp])*mu(theta,l,lp,-1)\n",
    "    return paddle.abs(norm)\n",
    "#计算cost function\n",
    "def local_cost(theta):\n",
    "    #当A｜x>和|b>同方向时，该值越接近0\n",
    "    mu_sum = 0\n",
    "    mu_sum = paddle.to_tensor(mu_sum,dtype = 'complex128')\n",
    "    #对每一个A0-2\n",
    "    for l in range(0, c.size):\n",
    "        for lp in range(0, c.size):\n",
    "            for j in range(0, num_qubit):\n",
    "                mu_sum = mu_sum + c[l] * paddle.conj(c[lp]) * mu(theta, l, lp, j)\n",
    "    \n",
    "    mu_sum = paddle.abs(mu_sum)\n",
    "    m1 = num_qubit * psi_norm(theta)\n",
    "    result = 0.5 - 0.5 * mu_sum / m1\n",
    "    # Cost function C_L\n",
    "    return result\n"
   ]
  },
  {
   "source": [
    "## 优化--梯度下降\n",
    "利用adam优化器，对角度参数$theta$进行优化，使得loss值不断减小，即$V|0\\rangle - |b\\rangle$趋于0  \n",
    "要调用优化器时，涉及到的计算参数必须是paddle形式的计算 如果是numpy形式无法处理"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vqlsOpt(paddle.nn.Layer):\n",
    "    def __init__(self, shape, dtype='float64'):\n",
    "        super(vqlsOpt, self).__init__()\n",
    "        # 初始化 theta 参数列表，并用 [0, 2*pi] 的均匀分布来填充初始值\n",
    "        self.theta = self.create_parameter(shape=shape,default_initializer=paddle.nn.initializer.Uniform(low=0.0, high=2*np.pi), dtype=dtype, is_bias=False)\n",
    "        \n",
    "    # 定义损失函数和前向传播机制\n",
    "    def forward(self):\n",
    "        # #初始化电路\n",
    "        # cir_v = UAnsatz(num_qubit)\n",
    "        # U = variational_block(cir_v,self.theta)\n",
    "        #计算损失函数\n",
    "        loss = local_cost(self.theta)\n",
    "        return loss"
   ]
  },
  {
   "source": [
    "## 迭代优化\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iter: 1   loss: 0.1444442\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-369-c6efe96aac55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mITR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 前向传播计算损失函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvqls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 反向传播极小化损失函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/paddle_quantum_env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-368-bbc2f1b55c15>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# U = variational_block(cir_v,self.theta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#计算损失函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-367-d18712e62c14>\u001b[0m in \u001b[0;36mlocal_cost\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_qubit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mmu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu_sum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-366-94f7634abeca>\u001b[0m in \u001b[0;36mmu\u001b[0;34m(theta, l, lp, j)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# print('mu: l,lp,j= ',l,lp,j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmu_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_hadamard_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Re'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmu_imag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_hadamard_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Im'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mjj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'complex128'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmuval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu_real\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mmu_imag\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-365-c21bd550ef8c>\u001b[0m in \u001b[0;36mlocal_hadamard_test\u001b[0;34m(theta, l, lp, j, part)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mcir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#对辅助比特为｜0>进行观测\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mfi_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_state_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfi_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtot_qubits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# 构造投影矩阵M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/paddle_quantum_env/lib/python3.7/site-packages/paddle_quantum/circuit.py\u001b[0m in \u001b[0;36mrun_state_vector\u001b[0;34m(self, input_state, store_state)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;34m'Input state is not a normalized vector'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer_by_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstore_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/paddle_quantum_env/lib/python3.7/site-packages/paddle_quantum/intrinsic.py\u001b[0m in \u001b[0;36mtransfer_by_history\u001b[0;34m(state, history)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhistory_ele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhistory_ele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'channel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateTransfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_ele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_ele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory_ele\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/paddle_quantum_env/lib/python3.7/site-packages/paddle_quantum/simulator.py\u001b[0m in \u001b[0;36mStateTransfer\u001b[0;34m(state, gate_name, bits, params)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gate name error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/paddle_quantum_env/lib/python3.7/site-packages/paddle_quantum/simulator.py\u001b[0m in \u001b[0;36mtransfer_state\u001b[0;34m(state, gate_matrix, bits)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;31m# restore compressed moveaxis reshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompressed_shape_after_moveaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplex_moveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompressed_source_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/paddle_quantum_env/lib/python3.7/site-packages/paddle/tensor/manipulation.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(x, shape, name)\u001b[0m\n\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m     \"\"\"\n\u001b[1;32m   1476\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0moperator\u001b[0m \u001b[0mchanges\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mshape\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwithout\u001b[0m \u001b[0mchanging\u001b[0m \u001b[0mits\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 定义网络维度\n",
    "paddle.seed(seed)\n",
    "theta_size = 9\n",
    "vqls = vqlsOpt(shape = [theta_size])\n",
    "# 一般来说，我们利用Adam优化器来获得相对好的收敛，当然你可以改成SGD或者是RMS prop.\n",
    "opt = paddle.optimizer.Adam(learning_rate = LR, parameters = vqls.parameters())    \n",
    "# 优化循环\n",
    "for itr in range(1,ITR+1):\n",
    "    # 前向传播计算损失函数\n",
    "    loss = vqls()\n",
    "    # 反向传播极小化损失函数\n",
    "    loss.backward()\n",
    "    opt.minimize(loss)\n",
    "    opt.clear_grad()\n",
    "    print('iter:', itr, '  loss: %.7f' % loss.numpy())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\nTensor(shape=[9], dtype=float64, place=CPUPlace, stop_gradient=False,\n       [4.71164075, 2.48129401, 1.28693871, 7.31129366, 1.78438510, 0.28329988, 2.59661299, 1.45937653, 4.70926758])\n"
     ]
    }
   ],
   "source": [
    "print(vqls.theta)"
   ]
  },
  {
   "source": [
    "## 量子电路结果和经典结果比较\n",
    "获得优化器中最终的$theta$参数列表，重新初始化量子门电路$V$，带入参数$theta$，观察计算结果"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.27651068+0.j 0.26920611+0.j 0.4088835 +0.j 0.40291999+0.j\n 0.28080338+0.j 0.29117207+0.j 0.42146475+0.j 0.42458856+0.j]\n"
     ]
    }
   ],
   "source": [
    "#验证\n",
    "weight = vqls.theta\n",
    "\n",
    "def prepare_x(theta):\n",
    "    cir_test = UAnsatz(num_qubit)\n",
    "    a = variational_block(cir_test,theta)\n",
    "    x_0 = cir_test.run_state_vector()\n",
    "    print(x_0.numpy())\n",
    "prepare_x(weight)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "source": [
    "## 传统numpy方法计算\n",
    "$Ax=b$ 计算得到x的真实值 用于和量子方法进行对比"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A = \n",
      " [[1.  0.  0.  0.  0.4 0.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0.4 0.  0. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1.  0.  0.  0.  0. ]\n",
      " [0.4 0.  0.  0.  1.  0.  0.  0. ]\n",
      " [0.  0.4 0.  0.  0.  1.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  1.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  1. ]]\n",
      "b = \n",
      " [0.35355339 0.35355339 0.35355339 0.35355339 0.35355339 0.35355339\n",
      " 0.35355339 0.35355339]\n",
      "x = \n",
      " [0.25253814 0.25253814 0.35355339 0.35355339 0.25253814 0.25253814\n",
      " 0.35355339 0.35355339]\n",
      "[0.2906191  0.2906191  0.40686674 0.40686674 0.2906191  0.2906191\n",
      " 0.40686674 0.40686674]\n",
      "/usr/local/anaconda3/envs/paddle_quantum_env/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "Id = np.identity(2)\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "ct = [1,0.2,0.2]\n",
    "A_0 = np.identity(8)\n",
    "A_1 = np.kron(np.kron(X, Z), Id)\n",
    "A_2 = np.kron(np.kron(X, Id), Id)\n",
    "\n",
    "A_num = ct[0] * A_0 + ct[1] * A_1 + ct[2] * A_2\n",
    "b = np.ones(8) / np.sqrt(8)\n",
    "print(\"A = \\n\", A_num)\n",
    "print(\"b = \\n\", b)\n",
    "A_inv = np.linalg.inv(A_num)\n",
    "x_real = np.dot(A_inv, b)\n",
    "print('x = \\n',x_real)\n",
    "print(x_real / (x_real**2).sum()**0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}