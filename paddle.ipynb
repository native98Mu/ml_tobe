{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0c4d8b35612f864a2161f1b44be3b413abd650f576ad681ae930eb27f85d4602e",
   "display_name": "Python 3.8.5 64-bit ('paddle_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 量子计算--palldle基础知识\n",
    "## Tensor基本介绍\n",
    "## 广播(broadcasting)介绍\n",
    "## 自动微分机制"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor(shape=[3], dtype=float64, place=CPUPlace, stop_gradient=True,\n",
      "       [2., 3., 4.])\n",
      "/usr/local/anaconda3/envs/paddle_env/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "#dtype支持：'bool'，'float16'，'float32'，'float64'，'uint8'，'int8'，'int16'，'int32'，'int64'\n",
    "# 可通过dtype来指定Tensor数据类型，否则会创建float32类型或int64的Tensor\n",
    "ndim_1_tensor = paddle.to_tensor([2.0, 3.0, 4.0], dtype='float64')\n",
    "print(ndim_1_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/anaconda3/envs/paddle_env/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Tensor(shape=[1], dtype=int64, place=CPUPlace, stop_gradient=True,\n",
       "       [2])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "paddle.to_tensor(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor(shape=[2, 3], dtype=float32, place=CPUPlace, stop_gradient=True,\n       [[1., 2., 3.],\n        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "ndim_2_tensor = paddle.to_tensor([[1.0, 2.0, 3.0],\n",
    "                                  [4.0, 5.0, 6.0]])\n",
    "print(ndim_2_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor(shape=[2, 2, 5], dtype=int64, place=CPUPlace, stop_gradient=True,\n       [[[1 , 2 , 3 , 4 , 5 ],\n         [6 , 7 , 8 , 9 , 10]],\n\n        [[11, 12, 13, 14, 15],\n         [16, 17, 18, 19, 20]]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor可以有任意数量的轴（也称为维度）\n",
    "ndim_3_tensor = paddle.to_tensor([[[1, 2, 3, 4, 5],\n",
    "                                   [6, 7, 8, 9, 10]],\n",
    "                                  [[11, 12, 13, 14, 15],\n",
    "                                   [16, 17, 18, 19, 20]]])\n",
    "print(ndim_3_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#tensor转为Numpy array\n",
    "ndim_2_tensor.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#支持复数\n",
    "ndim_2_complex_tensor = paddle.to_tensor([[1+1j, 2+2j],\n",
    "                                          [3+3j, 4+4j]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/anaconda3/envs/paddle_env/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#用Numpy array来创建Tensor\n",
    "ndim_1_tensor = paddle.to_tensor(np.array([1.0, 2.0]))\n",
    "\n",
    "ndim_2_tensor = paddle.to_tensor(np.array([[1.0, 2.0],\n",
    "                                              [3.0, 4.0]]))\n",
    "\n",
    "ndim_3_tensor = paddle.to_tensor(np.random.rand(3, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 2 3]\n",
      "/usr/local/anaconda3/envs/paddle_env/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "paddle.arange(1,10,2)\n",
    "arr = np.array([1,2,3])\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data Type of every element: VarType.FP32\nNumber of dimensions: 4\nShape of tensor: [2, 3, 4, 5]\nElements number along axis 0 of tensor: 2\nElements number along the last axis of tensor: 5\n"
     ]
    }
   ],
   "source": [
    "ndim_4_tensor = paddle.ones([2,3,4,5])\n",
    "#print(ndim_4_tensor)\n",
    "print(\"Data Type of every element:\", ndim_4_tensor.dtype)\n",
    "print(\"Number of dimensions:\", ndim_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", ndim_4_tensor.shape)\n",
    "print(\"Elements number along axis 0 of tensor:\", ndim_4_tensor.shape[0])\n",
    "print(\"Elements number along the last axis of tensor:\", ndim_4_tensor.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the shape of ndim_3_tensor: [3, 2, 5]\nAfter reshape: [2, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "#tensor的reshape 改变结构\n",
    "ndim_3_tensor = paddle.to_tensor([[[1, 2, 3, 4, 5],\n",
    "                                   [6, 7, 8, 9, 10]],\n",
    "                                  [[11, 12, 13, 14, 15],\n",
    "                                   [16, 17, 18, 19, 20]],\n",
    "                                  [[21, 22, 23, 24, 25],\n",
    "                                   [26, 27, 28, 29, 30]]])\n",
    "print(\"the shape of ndim_3_tensor:\", ndim_3_tensor.shape)\n",
    "ndim_3_tensor = paddle.reshape(ndim_3_tensor, [2, 5, 3])\n",
    "print(\"After reshape:\", ndim_3_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor dtype from Python integers: VarType.INT64\nTensor dtype from Python floating point: VarType.FP32\nTensor after cast to float64: VarType.FP64\nTensor after cast to int64: VarType.INT64\n"
     ]
    }
   ],
   "source": [
    "#通过Numpy array创建的Tensor，则与其原来的dtype保持相同\n",
    "print(\"Tensor dtype from Python integers:\", paddle.to_tensor(1).dtype)\n",
    "print(\"Tensor dtype from Python floating point:\", paddle.to_tensor(1.0).dtype)\n",
    "#通过cast接口改变dtype\n",
    "float32_tensor = paddle.to_tensor(1.0)\n",
    "\n",
    "float64_tensor = paddle.cast(float32_tensor, dtype='float64')\n",
    "print(\"Tensor after cast to float64:\", float64_tensor.dtype)\n",
    "\n",
    "int64_tensor = paddle.cast(float32_tensor, dtype='int64')\n",
    "print(\"Tensor after cast to int64:\", int64_tensor.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor(shape=[1], dtype=int64, place=CPUPlace, stop_gradient=True,\n       [1])\nTensor name: generated_tensor_50\n"
     ]
    }
   ],
   "source": [
    "#创建CPU上的Tensor\n",
    "cpu_tensor = paddle.to_tensor(1, place=paddle.CPUPlace())\n",
    "print(cpu_tensor)\n",
    "#Tensor的name\n",
    "print(\"Tensor name:\", paddle.to_tensor(1).name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Origin Tensor: [0 1 2 3 4 5 6 7 8]\n",
      "Tensor(shape=[9], dtype=int64, place=CPUPlace, stop_gradient=True,\n",
      "       [0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "First element: [0]\n",
      "Last element: [8]\n",
      "All element: [0 1 2 3 4 5 6 7 8]\n",
      "Before 3: [0 1 2]\n",
      "From 6 to the end: [6 7 8]\n",
      "From 3 to 6: [3 4 5]\n",
      "Interval of 3: [0 3 6]\n",
      "Reverse: [8 7 6 5 4 3 2 1 0]\n",
      "/usr/local/anaconda3/envs/paddle_env/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Tensor的索引和切片\n",
    "ndim_1_tensor = paddle.to_tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "print(\"Origin Tensor:\", ndim_1_tensor.numpy())\n",
    "print(ndim_1_tensor)\n",
    "print(\"First element:\", ndim_1_tensor[0].numpy())\n",
    "print(\"Last element:\", ndim_1_tensor[-1].numpy())\n",
    "print(\"All element:\", ndim_1_tensor[:].numpy())\n",
    "print(\"Before 3:\", ndim_1_tensor[:3].numpy())\n",
    "print(\"From 6 to the end:\", ndim_1_tensor[6:].numpy())\n",
    "print(\"From 3 to 6:\", ndim_1_tensor[3:6].numpy())\n",
    "print(\"Interval of 3:\", ndim_1_tensor[::3].numpy())\n",
    "print(\"Reverse:\", ndim_1_tensor[::-1].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Origin Tensor: [[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]]\n[3, 4]\nFirst row: [0 1 2 3]\nFirst row: [0 1 2 3]\nFirst column: [0 4 8]\nLast column: [ 3  7 11]\n1:2 Tensor(shape=[1, 4], dtype=int64, place=CPUPlace, stop_gradient=True,\n       [[8 , 9 , 10, 11]])\nAll element: [[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]]\nFirst row and second column: [1]\n"
     ]
    }
   ],
   "source": [
    "#多维tensor索引或切片\n",
    "#第一个值对应axis0 第二个对应axis2\n",
    "ndim_2_tensor = paddle.to_tensor([[0, 1, 2, 3],\n",
    "                                  [4, 5, 6, 7],\n",
    "                                  [8, 9, 10, 11]])\n",
    "print(\"Origin Tensor:\", ndim_2_tensor.numpy())\n",
    "print(ndim_2_tensor.shape)\n",
    "print(\"First row:\", ndim_2_tensor[0].numpy())\n",
    "print(\"First row:\", ndim_2_tensor[0, :].numpy())\n",
    "print(\"First column:\", ndim_2_tensor[:, 0].numpy())\n",
    "print(\"Last column:\", ndim_2_tensor[:, -1].numpy())\n",
    "print('2:3',ndim_2_tensor[2:3])\n",
    "print(\"All element:\", ndim_2_tensor[:].numpy())\n",
    "print(\"First row and second column:\", ndim_2_tensor[0, 1].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor(shape=[2, 2], dtype=float64, place=CPUPlace, stop_gradient=True,\n       [[6.60000000 , 8.80000000 ],\n        [11.        , 13.20000000]]) \n\nTensor(shape=[2, 2], dtype=float64, place=CPUPlace, stop_gradient=True,\n       [[6.60000000 , 8.80000000 ],\n        [11.        , 13.20000000]]) \n\n"
     ]
    }
   ],
   "source": [
    "#多种数学API\n",
    "#paddle操作均为非inplace操作，即返回一个新的tensor表示运算结果\n",
    "x = paddle.to_tensor([[1.1, 2.2], [3.3, 4.4]], dtype=\"float64\")\n",
    "y = paddle.to_tensor([[5.5, 6.6], [7.7, 8.8]], dtype=\"float64\")\n",
    "\n",
    "print(paddle.add(x, y), \"\\n\")\n",
    "print(x.add(y), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数学运算符\n",
    "x.abs()                       #逐元素取绝对值\n",
    "x.ceil()                      #逐元素向上取整\n",
    "x.floor()                     #逐元素向下取整\n",
    "x.round()                     #逐元素四舍五入\n",
    "x.exp()                       #逐元素计算自然常数为底的指数\n",
    "x.log()                       #逐元素计算x的自然对数\n",
    "x.reciprocal()                #逐元素求倒数\n",
    "x.square()                    #逐元素计算平方\n",
    "x.sqrt()                      #逐元素计算平方根\n",
    "x.sin()                       #逐元素计算正弦\n",
    "x.cos()                       #逐元素计算余弦\n",
    "x.add(y)                      #逐元素相加\n",
    "x.subtract(y)                 #逐元素相减\n",
    "x.multiply(y)                 #逐元素相乘\n",
    "x.divide(y)                   #逐元素相除\n",
    "x.mod(y)                      #逐元素相除并取余\n",
    "x.pow(y)                      #逐元素幂运算\n",
    "x.max()                       #指定维度上元素最大值，默认为全部维度\n",
    "x.min()                       #指定维度上元素最小值，默认为全部维度\n",
    "x.prod()                      #指定维度上元素累乘，默认为全部维度\n",
    "x.sum()                       #指定维度上元素的和，默认为全部维度\n",
    "'''\n",
    "x + y  -> x.add(y)            #逐元素相加\n",
    "x - y  -> x.subtract(y)       #逐元素相减\n",
    "x * y  -> x.multiply(y)       #逐元素相乘\n",
    "x / y  -> x.divide(y)         #逐元素相除\n",
    "x % y  -> x.mod(y)            #逐元素相除并取余\n",
    "x ** y -> x.pow(y)            #逐元素幂运算\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#逻辑运算符\n",
    "x.isfinite()                  #判断tensor中元素是否是有限的数字，即不包括inf与nan\n",
    "x.equal_all(y)                #判断两个tensor的全部元素是否相等，并返回shape为[1]的bool Tensor\n",
    "x.equal(y)                    #判断两个tensor的每个元素是否相等，并返回shape相同的bool Tensor\n",
    "x.not_equal(y)                #判断两个tensor的每个元素是否不相等\n",
    "x.less_than(y)                #判断tensor x的元素是否小于tensor y的对应元素\n",
    "x.less_equal(y)               #判断tensor x的元素是否小于或等于tensor y的对应元素\n",
    "x.greater_than(y)             #判断tensor x的元素是否大于tensor y的对应元素\n",
    "x.greater_equal(y)            #判断tensor x的元素是否大于或等于tensor y的对应元素\n",
    "x.allclose(y)                 #判断tensor x的全部元素是否与tensor y的全部元素接近，并返回shape为[1]的bool Tensor\n",
    "'''\n",
    "x == y  -> x.equal(y)         #判断两个tensor的每个元素是否相等\n",
    "x != y  -> x.not_equal(y)     #判断两个tensor的每个元素是否不相等\n",
    "x < y   -> x.less_than(y)     #判断tensor x的元素是否小于tensor y的对应元素\n",
    "x <= y  -> x.less_equal(y)    #判断tensor x的元素是否小于或等于tensor y的对应元素\n",
    "x > y   -> x.greater_than(y)  #判断tensor x的元素是否大于tensor y的对应元素\n",
    "x >= y  -> x.greater_equal(y) #判断tensor x的元素是否大于或等于tensor y的对应元素\n",
    "\n",
    "'''\n",
    "'''\n",
    "#仅针对布尔型变量\n",
    "x.logical_and(y)              #对两个bool型tensor逐元素进行逻辑与操作\n",
    "x.logical_or(y)               #对两个bool型tensor逐元素进行逻辑或操作\n",
    "x.logical_xor(y)              #对两个bool型tensor逐元素进行逻辑亦或操作\n",
    "x.logical_not(y)              #对两个bool型tensor逐元素进行逻辑非操作\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#线性代数相关\n",
    "x.cholesky()                  #矩阵的cholesky分解\n",
    "x.t()                         #矩阵转置\n",
    "x.transpose([1, 0])           #交换axis 0 与axis 1的顺序\n",
    "x.norm('fro')                 #矩阵的Frobenius 范数\n",
    "x.dist(y, p=2)                #矩阵（x-y）的2范数\n",
    "x.matmul(y)                   #矩阵乘法\n"
   ]
  },
  {
   "source": [
    "### 张量广播\n",
    "从后往前比较张量的形状，当前维度的大小要么相等，要么其中一个等于一，要么其中一个不存在  \n",
    "如果两个张量的形状的长度不一致，那么需要在较小形状长度的矩阵向前添加1，直到两个张量的形状长度相等。\n",
    "\n",
    "保证两个张量形状相等之后，每个维度上的结果维度就是当前维度上较大的那个。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor(shape=[2, 3, 4], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]]])\n",
      "[2, 3, 4, 5]\n",
      "Tensor(shape=[2, 3, 4, 5], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]]]])\n",
      "/usr/local/anaconda3/envs/paddle_env/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "x = paddle.ones((2,3,4))\n",
    "y = paddle.ones((2,3,4))\n",
    "z = x + y\n",
    "print(z)\n",
    "x = paddle.ones((2, 3, 1, 5))\n",
    "y = paddle.ones((3, 4, 1))\n",
    "# 从后向前依次比较：\n",
    "# 第一次：y的维度大小是1\n",
    "# 第二次：x的维度大小是1\n",
    "# 第三次：x和y的维度大小相等\n",
    "# 第四次：y的维度不存在\n",
    "# 所以 x和y是可以广播的\n",
    "z = x + y\n",
    "print(z.shape)\n",
    "# [2, 3, 4, 5]\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}