{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e5d5a545d47a452400ed0f023be4625769e773074f6a65de0103e9cc8585fc80",
   "display_name": "Python 3.8.5 64-bit ('paddle_quantum_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 线性系统求解\n",
    "Ax = b,$$A = c_0A_0+c_1A_1+c_2A_2=\\mathbb{I}+0.2X_0Z_1+0.2X_0$$\n",
    "$$|b\\rangle = U|0\\rangle = H_0H_1H_2|0\\rangle$$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import paddle \n",
    "from paddle import matmul\n",
    "from paddle_quantum.circuit import UAnsatz\n",
    "from paddle_quantum.utils import random_pauli_str_generator, pauli_str_to_matrix, dagger\n",
    "#参数设置\n",
    "num_qubit = 3  \n",
    "num_shots = 10**6 # Number of quantum measurements\n",
    "tot_qubits = num_qubit+1 # Addition of an ancillary qubit\n",
    "ancilla_idx = num_qubit #Index of the ancillary qubit (last position)\n",
    "ITR = 80 #训练迭代次数\n",
    "LR = 0.5 #学习速率\n",
    "seed = 0 # Seed for random number generator\n",
    "#构造cz gate\n",
    "a= np.array([np.pi/2])\n",
    "cz_theta = paddle.to_tensor(a)\n",
    "#coefficient of A=c_0 A_0 + c_1 A_1 ...\n",
    "c = np.array([1,0.2,0.2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义门电路U和A\n",
    "def U_b():\n",
    "    for idx in range(num_qubit):\n",
    "        cir.h(idx)\n",
    "def CA(idx):\n",
    "    if idx == 0:\n",
    "        # Identity operation\n",
    "        None\n",
    "    elif idx == 1:\n",
    "        cir.cnot([ancilla_idx,0])\n",
    "        #cz gate\n",
    "        cir.s(ancilla_idx)\n",
    "        cir.s(ancilla_idx)\n",
    "        cir.s(ancilla_idx)\n",
    "        cir.cnot([ancilla_idx,1])\n",
    "        cir.rz(cz_theta,1)\n",
    "        cir.cnot([ancilla_idx,1])\n",
    "        cir.rz(-cz_theta,1)\n",
    "    elif idx == 2:\n",
    "        cir.cnot([ancilla_idx, 0])\n",
    "#定义变分量子电路 使得|x> = V|0>\n",
    "def variational_block(theta):\n",
    "    '''\n",
    "    QNN\n",
    "    '''\n",
    "    #第一层是给除附加位外所有量子比特施加h门\n",
    "    for idx in range(num_qubit):\n",
    "        cir.h(idx)\n",
    "    #单层的全y门\n",
    "    for idx, element in enumerate(theta):\n",
    "        cir.ry(element,idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hadamard test\n",
    "def local_hadamard_test(theta,l = None,lp=None,j = None,part = None):\n",
    "    #初始化电路\n",
    "    cir = UAnsatz(tot_qubits)#需要附加位\n",
    "    #作用在附加位上的H门\n",
    "    cir.h(ancilla_idx)\n",
    "    #如果要计算的是虚数部，附加位还需要加一个相位门\n",
    "    #phase gate\n",
    "    if part == 'Im' or part == 'im':\n",
    "        cir.s(ancilla_idx)\n",
    "    #生成一个向量｜x>\n",
    "    variational_block(theta)\n",
    "    #使用A_l\n",
    "    CA(l)\n",
    "    #添加U_b\n",
    "    U_b()\n",
    "    #添加受控z\n",
    "    if j != -1:\n",
    "        #cz gate\n",
    "        cir.s(ancilla_idx)\n",
    "        cir.s(ancilla_idx)\n",
    "        cir.s(ancilla_idx)\n",
    "        cir.cnot([ancilla_idx,j])\n",
    "        cir.rz(cz_theta,j)\n",
    "        cir.cnot([ancilla_idx,j])\n",
    "        cir.rz(-cz_theta,j)\n",
    "    #添加U\n",
    "    U_b()\n",
    "    #contralled gate为A的伴随矩阵\n",
    "    CA(lp)\n",
    "    #辅助位第二个hadamard门\n",
    "    cir.h(ancilla_idx)\n",
    "    #对辅助比特为｜0>进行观测\n",
    "    fi_state = cir.run_state_vector()\n",
    "    state = paddle.reshape(fi_state, shape=(2**tot_qubits, 1))\n",
    "    # print(state.shape)\n",
    "    M_0 = np.array([[1,0],[0,0]])\n",
    "    Id = np.identity(2)\n",
    "    M = np.kron(np.kron(Id,Id),Id)\n",
    "    M = np.kron(M,M_0)\n",
    "    M = paddle.to_tensor(M)\n",
    "    #计算辅助位｜0>的概率\n",
    "    M = paddle.matmul(dagger(M), M)\n",
    "    p0 = paddle.matmul(paddle.matmul(dagger(state), M), state) \n",
    "    p0 = p0.numpy().real\n",
    "    return p0*2 - 1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算local cost function的系数\n",
    "def mu(theta,l = None,lp=None,j=None):\n",
    "    mu_real = local_hadamard_test(theta,l = l,lp = lp,j = j,part='Re')\n",
    "    mu_imag = local_hadamard_test(theta,l = l, lp = lp, j = j, part= 'Im')\n",
    "    return mu_real + mu_imag * 1.0j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化 先计算 <x|A'A|x>\n",
    "def psi_norm(theta):\n",
    "    '''Returns the normalization constant <psi|psi>, where |psi> = A |x>.'''\n",
    "    norm = 0\n",
    "    for l in range(len(c)):\n",
    "        for lp in range(len(c)):\n",
    "            norm = norm+c[l]*np.conj(c[lp])*mu(theta,l,lp,-1)\n",
    "            # norm = norm + c[l]*np.conj(c[lp])\n",
    "    return abs(norm)\n",
    "#计算cost function\n",
    "def local_cost(theta):\n",
    "    #当A｜x>和|b>同方向时，该值越接近0\n",
    "    mu_sum = 0\n",
    "    #\n",
    "    for l in range(0, len(c)):\n",
    "        for lp in range(0, len(c)):\n",
    "            for j in range(0, num_qubit):\n",
    "                mu_sum = mu_sum + c[l] * np.conj(c[lp]) * mu(theta, l, lp, j)\n",
    "\n",
    "    mu_sum = abs(mu_sum)\n",
    "    m1 = num_qubit * psi_norm(theta)\n",
    "    result = 0.5 - 0.5 * mu_sum / m1\n",
    "    # Cost function C_L\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.54841453 3.62582236 0.84280363]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cir' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fdff21d388e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mlocal_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# print('%.10f' %loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-60bf0edfcbc2>\u001b[0m in \u001b[0;36mlocal_cost\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_qubit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mmu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu_sum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5767518526bb>\u001b[0m in \u001b[0;36mmu\u001b[0;34m(theta, l, lp, j)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#计算local cost function的系数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmu_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_hadamard_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Re'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmu_imag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_hadamard_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Im'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmu_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmu_imag\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-ac38ed6cd840>\u001b[0m in \u001b[0;36mlocal_hadamard_test\u001b[0;34m(theta, l, lp, j, part)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancilla_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#生成一个向量｜x>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvariational_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#使用A_l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9bcaa6f52dc7>\u001b[0m in \u001b[0;36mvariational_block\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#第一层是给除附加位外所有量子比特施加h门\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_qubit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m#单层的全y门\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cir' is not defined"
     ]
    }
   ],
   "source": [
    "theta = np.random.uniform(0,2*np.pi,num_qubit)\n",
    "print(theta)\n",
    "theta = paddle.to_tensor(theta)\n",
    "loss =local_cost(theta)\n",
    "# print('%.10f' %loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vqlsOpt(paddle.nn.Layer):\n",
    "        # 初始化一个长度为theta_size的可学习参数列表，并用[0, 2*pi]的均匀分布来填充初始值\n",
    "    # def __init__(self):    \n",
    "        # self.theta = np.random.uniform(0,2*np.pi,num_qubit)\n",
    "    def __init__(self, shape, dtype='float64'):\n",
    "        super(vqlsOpt, self).__init__()\n",
    "        # 初始化 theta 参数列表，并用 [0, 2*pi] 的均匀分布来填充初始值\n",
    "        self.theta = self.create_parameter(shape=shape,default_initializer=paddle.nn.initializer.Uniform(low=0.0, high=2*np.pi), dtype=dtype, is_bias=False)\n",
    "    # 定义损失函数和前向传播机制\n",
    "    def forward(self):\n",
    "        #计算损失函数\n",
    "        loss = local_cost(theta)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/anaconda3/envs/paddle_quantum_env/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'vqlsOpt' object has no attribute 'create_parameter'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-440-5e1ba605f056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 定义网络维度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvqls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvqlsOpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# 一般来说，我们利用Adam优化器来获得相对好的收敛，当然你可以改成SGD或者是RMS prop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvqls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 优化循环\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-430-9d6d38891627>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvqlsOpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# 初始化 theta 参数列表，并用 [0, 2*pi] 的均匀分布来填充初始值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdefault_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 定义损失函数和前向传播机制\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'vqlsOpt' object has no attribute 'create_parameter'"
     ]
    }
   ],
   "source": [
    "# 定义网络维度\n",
    "vqls = vqlsOpt(shape = [1])\n",
    "# 一般来说，我们利用Adam优化器来获得相对好的收敛，当然你可以改成SGD或者是RMS prop.\n",
    "opt = paddle.optimizer.Adam(learning_rate = LR, parameters = vqls.parameters())    \n",
    "# 优化循环\n",
    "for itr in range(1,ITR+1):\n",
    "    # 前向传播计算损失函数\n",
    "    loss = vqls()\n",
    "    # 反向传播极小化损失函数\n",
    "    loss.backward()\n",
    "    opt.minimize(loss)\n",
    "    opt.clear_grad()\n",
    "    # 记录学习曲线\n",
    "    loss_list.append(loss.numpy())\n",
    "    if itr % 10 == 0:\n",
    "        print('iter:', itr, '  loss: %.4f' % loss.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A = \n [[1.  0.  0.  0.  0.4 0.  0.  0. ]\n [0.  1.  0.  0.  0.  0.4 0.  0. ]\n [0.  0.  1.  0.  0.  0.  0.  0. ]\n [0.  0.  0.  1.  0.  0.  0.  0. ]\n [0.4 0.  0.  0.  1.  0.  0.  0. ]\n [0.  0.4 0.  0.  0.  1.  0.  0. ]\n [0.  0.  0.  0.  0.  0.  1.  0. ]\n [0.  0.  0.  0.  0.  0.  0.  1. ]]\nb = \n [0.35355339 0.35355339 0.35355339 0.35355339 0.35355339 0.35355339\n 0.35355339 0.35355339]\n[0.25253814 0.25253814 0.35355339 0.35355339 0.25253814 0.25253814\n 0.35355339 0.35355339]\n"
     ]
    }
   ],
   "source": [
    "Id = np.identity(2)\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "\n",
    "A_0 = np.identity(8)\n",
    "A_1 = np.kron(np.kron(X, Z), Id)\n",
    "A_2 = np.kron(np.kron(X, Id), Id)\n",
    "\n",
    "A_num = c[0] * A_0 + c[1] * A_1 + c[2] * A_2\n",
    "b = np.ones(8) / np.sqrt(8)\n",
    "print(\"A = \\n\", A_num)\n",
    "print(\"b = \\n\", b)\n",
    "A_inv = np.linalg.inv(A_num)\n",
    "x = np.dot(A_inv, b)\n",
    "c_probs = (x / np.linalg.norm(x)) ** 2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "#验证\n",
    "import paddle\n",
    "from paddle_quantum.circuit import UAnsatz\n",
    "cir = UAnsatz(num_qubit)\n",
    "def prepare_x(theta):\n",
    "    variational_block(theta)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}